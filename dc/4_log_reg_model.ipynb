{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model\n",
    "Logistic Regression a generalized Linear Model with a straightforward implementation and fast compute times. These qualities make LR a great benchmark before moving on to more complex modeling. Some of it's strengths include low variance, resiliance against overfitting, and a nice probabalistic ouput which makes for easy interpretation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Time Series Split assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('../assets/X_train.pkl')\n",
    "X_test = pd.read_pickle('../assets/X_test.pkl')\n",
    "y_train = pd.read_pickle('../assets/y_train.pkl')\n",
    "y_test = pd.read_pickle('../assets/y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Day_length', 'Tmax', 'Tmin', 'Tavg', 'ResultSpeed', 'ResultDir',\n",
       "       'AvgSpeed', 'Sunset', 'Sunrise', 'Heat', 'Depart', 'DewPoint',\n",
       "       'WetBulb', 'Cool', 'PrecipTotal', 'StnPressure', 'Latitude',\n",
       "       'Longitude', 'Month', 'Day_length_exp', 'Tavg_shift', 'Heat_exp',\n",
       "       'Cool_shift', 'Tmax_shift', 'Tmin_shift', 'Depart_shift',\n",
       "       'ResultSpeed_shift', 'ResultDir_exp', 'PrecipTotal_exp', 'WetBulb_exp',\n",
       "       'Species_CULEX ERRATICUS', 'Species_CULEX PIPIENS',\n",
       "       'Species_CULEX PIPIENS/RESTUANS', 'Species_CULEX RESTUANS',\n",
       "       'Species_CULEX SALINARIUS', 'Species_CULEX TARSALIS',\n",
       "       'Species_CULEX TERRITANS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a pipeline\n",
    "We're optimizing the model first by scaling our values.\n",
    "Next we cycle through both L1 and L2 penalties to determine the optimum loss function for our model.\n",
    "Finally we iterate through c values between .001 and .95 which cycles through the the min and max of acceptable ranges. C is the inverse regularzation strength which controls the weight of the coefficients in our model. A higher c indicates a lower strength of regularization. After grid searching our best C turned out to be .95 which mean almost no regularization was applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('ss',StandardScaler()),\n",
    "    ('lr',LogisticRegression(solver='liblinear')),    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting a range of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid =  {\n",
    "    'lr__penalty':['l1','l2'],\n",
    "    'lr__C': np.linspace(.001,.95,50)\n",
    "        \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearching\n",
    "Gridsearching our parameter grid to get the best hyperparameters for our model. \n",
    "We set the scoring to roc_auc because of the low count of mosquitos with west nile in our train data. If we were to score on accuracy our model would never predict west nile because 95% of the data doesn't contain observations where mosquitos have west nile. Roc Auc punishes the model for not predicting west nile, therefore it's a better metric for our current application. \n",
    "We also did a time series split here because we felt that there was a strong spatiotemporal relationship in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=param_grid,verbose=1,scoring='roc_auc', cv=TimeSeriesSplit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:   17.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=3),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('ss', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'lr__penalty': ['l1', 'l2'], 'lr__C': array([0.001  , 0.02037, 0.03973, 0.0591 , 0.07847, 0.09784, 0.1172 ,\n",
       "       0.13657, 0.15594, 0.17531, 0.19467, 0.21404, 0.23341, 0.25278,\n",
       "       0.27214, 0.29151, 0.31088, 0.33024, 0.34961, 0.36898, 0.38835,\n",
       "       0.40771, 0.42708, 0.44645, 0.4658...69, 0.79506,\n",
       "       0.81443, 0.8338 , 0.85316, 0.87253, 0.8919 , 0.91127, 0.93063,\n",
       "       0.95   ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring \n",
    "The scoring metric used to evaluate our model was roc_auc. ROC_AUC is an aggregate measure of performance across all classification thresholds, it returns a float between 0 and 1. A score of 0 demonstrates a poor classifier that is wrong 100% of the time. A score of 1 indicates a strong classifier that is right 100% of the time. \n",
    "We scored an .86 on our training data and a .76 on our test data. We interpreted the outcome of our modeling with catious optimism. We feel confident that this model can be used to shape decisions regarding the frequency and location of pesticide application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8658258730915267"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7611057928963493"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the best parameters\n",
    "Checking the optimal parameters for our model as determined by our gridsearch.\n",
    "Our C value is .95 percent which indicates that we are applying almost no regularization. The loss function being used is L1 which is robust against outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 0.95, 'lr__penalty': 'l1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading coefficients into a dataframe\n",
    "Interpreting the feature weights gave us insight into what the model was using to predict the presence of west nile. Features like day length expanded mean and wetbulb contributed to our predictions positively. An interesting note is that the species culex pipiens, a known carrier of the disease is also a positive indicator for west nile in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.DataFrame(data=gs.best_estimator_.named_steps['lr'].coef_.T,\n",
    "                     index=X_train.columns,\n",
    "                     columns=['importance']\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../assets/logistic_regression.pkl','wb+') as f:\n",
    "#     pickle.dump(gs,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
